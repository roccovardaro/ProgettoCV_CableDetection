{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddab2ff5-a9f8-423f-81ee-672a777610cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:26:46.646786Z",
     "start_time": "2025-12-19T17:26:46.583223Z"
    }
   },
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from pycocotools import mask as coco_mask\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4323d517",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:26:47.936047Z",
     "start_time": "2025-12-19T17:26:47.933518Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_segmentation(gt_json_path, pred_json_path, check_cable_class=False):\n",
    "    # Load ground truth\n",
    "    coco_gt = COCO(gt_json_path)\n",
    "\n",
    "    # --- PATCH: Aggiungiamo le chiavi mancanti per evitare KeyError in loadRes ---\n",
    "    # La libreria pycocotools.COCO.loadRes si aspetta di copiare 'info' e 'licenses' \n",
    "    # dal Ground Truth ai risultati. Le aggiungiamo se non presenti.\n",
    "    if 'info' not in coco_gt.dataset:\n",
    "        coco_gt.dataset['info'] = {}\n",
    "    if 'licenses' not in coco_gt.dataset:\n",
    "        coco_gt.dataset['licenses'] = []\n",
    "    # --- FINE PATCH ---\n",
    "\n",
    "    # Load predictions\n",
    "    with open(pred_json_path, 'r') as f:\n",
    "        predictions = json.load(f)\n",
    "\n",
    "    # Load results into COCO results structure\n",
    "    coco_res = coco_gt.loadRes(predictions)\n",
    "\n",
    "    # Create COCOeval object\n",
    "    coco_eval = COCOeval(coco_gt, coco_res, 'segm')\n",
    "    if check_cable_class:\n",
    "        coco_eval.params.catIds = [0]  # id of the cable class\n",
    "\n",
    "    # Run evaluation\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "\n",
    "    avg_p50 = coco_eval.stats[1]\n",
    "    avg_r50 = coco_eval.stats[7]\n",
    "    return avg_p50, avg_r50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "777a2a74-01cf-466f-8fab-24e85edae40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_segmentation2(gt_json_path, pred_json_path, check_cable_class=False):\n",
    "    # Load ground truth\n",
    "    coco_gt = COCO(gt_json_path)\n",
    "\n",
    "    # Load predictions\n",
    "    with open(pred_json_path, 'r') as f:\n",
    "        predictions = json.load(f)\n",
    "\n",
    "    # Load results into COCO results structure\n",
    "    coco_res = coco_gt.loadRes(predictions)\n",
    "\n",
    "    # Create COCOeval object\n",
    "    coco_eval = COCOeval(coco_gt, coco_res, 'segm')\n",
    "    if check_cable_class:\n",
    "        coco_eval.params.catIds = [0]  # id of the cable class\n",
    "\n",
    "    # Run evaluation\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "\n",
    "    avg_p50 = coco_eval.stats[1]\n",
    "    avg_r50 = coco_eval.stats[7]\n",
    "    return avg_p50, avg_r50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4d3c92b-3ee9-43cd-8546-b550144dd5c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:26:50.280206Z",
     "start_time": "2025-12-19T17:26:50.249824Z"
    }
   },
   "outputs": [],
   "source": [
    "def combined_analysis(gt_annotation_file, prediction_file):\n",
    "    # Load ground truth data\n",
    "    with open(gt_annotation_file, 'r') as f:\n",
    "        gt_data = json.load(f)\n",
    "    # Load prediction data\n",
    "    with open(prediction_file, 'r') as f:\n",
    "        pred_data = json.load(f)\n",
    "    # Group GT lines by image id\n",
    "    gt_lines_by_image = defaultdict(list)\n",
    "    for ann in gt_data['annotations']:\n",
    "        image_id = ann['image_id']\n",
    "        if 'polar_coordinates' in ann:\n",
    "            lines = [(coord['rho'], coord['theta']) for coord in ann['polar_coordinates']]\n",
    "            gt_lines_by_image[image_id].extend(lines)\n",
    "        else:\n",
    "            raise RuntimeError(f'no polar coord for image id {image_id}')\n",
    "    # Group predictions by image id\n",
    "    pred_by_image = defaultdict(list)\n",
    "    for pred in pred_data:\n",
    "        pred_by_image[pred['image_id']].append(pred)\n",
    "    angle_diffs = []\n",
    "    rho_diffs = []\n",
    "    \n",
    "    def theta_diff(theta_pred, theta_gt):\n",
    "        t = min(abs(theta_pred - theta_gt), np.pi - abs(theta_pred - theta_gt))\n",
    "        return np.exp(-.12 * t)\n",
    "    \n",
    "    def polygons_to_mask(polygons, shape):\n",
    "        mask = np.zeros(shape, dtype=np.uint8)\n",
    "        for polygon in polygons:\n",
    "            pts = np.array(polygon).reshape((-1, 2)).astype(np.int32)\n",
    "            cv2.fillPoly(mask, [pts], color=255)\n",
    "        return mask\n",
    "    \n",
    "    def compute_iou(mask1, mask2):\n",
    "        intersection = np.logical_and(mask1, mask2).sum()\n",
    "        union = np.logical_or(mask1, mask2).sum()\n",
    "        return intersection / union if union > 0 else 0\n",
    "    \n",
    "    total_matches = 0\n",
    "    total_gt_lines = 0\n",
    "    total_pred_lines = 0\n",
    "    \n",
    "    for image_info in tqdm(gt_data['images']):\n",
    "        image_id = image_info['id']\n",
    "        height, width = image_info['height'], image_info['width']\n",
    "        \n",
    "        # Load predictions for this image\n",
    "        pred_masks = []\n",
    "        pred_lines = []\n",
    "        for pred in pred_by_image.get(image_id, []):\n",
    "            seg = pred['segmentation']\n",
    "            if isinstance(seg, list):\n",
    "                mask_poly = polygons_to_mask(seg, (height, width))\n",
    "                pred_masks.append(mask_poly)\n",
    "            elif isinstance(seg, dict) and 'counts' in seg and 'size' in seg:\n",
    "                mask_rle = coco_mask.decode(seg)\n",
    "                if mask_rle.ndim == 3:\n",
    "                    mask_rle = mask_rle[:, :, 0]\n",
    "                mask_rle = (mask_rle * 255).astype(np.uint8)\n",
    "                pred_masks.append(mask_rle)\n",
    "            else:\n",
    "                raise RuntimeError(f'[SEGM] unsupported format for image id {image_id}')\n",
    "            \n",
    "            # Extract predicted line if exists\n",
    "            if 'lines' in pred and len(pred['lines']) == 2:\n",
    "                rho, theta = pred['lines']\n",
    "                rho = np.abs(rho / np.sqrt(height**2 + width**2))\n",
    "                pred_lines.append((rho, theta))\n",
    "            else:\n",
    "                pred_lines.append(None)\n",
    "        \n",
    "        # Load ground truth masks for this image\n",
    "        gt_masks = []\n",
    "        gt_lines = []\n",
    "        for ann in gt_data['annotations']:\n",
    "            if ann['image_id'] == image_id:\n",
    "                seg = ann['segmentation']\n",
    "                if isinstance(seg, list):\n",
    "                    mask_poly = polygons_to_mask(seg, (height, width))\n",
    "                    gt_masks.append(mask_poly)\n",
    "                elif isinstance(seg, dict) and 'counts' in seg and 'size' in seg:\n",
    "                    mask_rle = coco_mask.decode(seg)\n",
    "                    if mask_rle.ndim == 3:\n",
    "                        mask_rle = mask_rle[:, :, 0]\n",
    "                    mask_rle = (mask_rle * 255).astype(np.uint8)\n",
    "                    gt_masks.append(mask_rle)\n",
    "                else:\n",
    "                    raise RuntimeError(f'[GT] unsupported format for image id {image_id}')\n",
    "                \n",
    "                # Extract GT line\n",
    "                if 'polar_coordinates' in ann and len(ann['polar_coordinates']) > 0:\n",
    "                    rho, theta = ann['polar_coordinates'][0]['rho'], ann['polar_coordinates'][0]['theta']\n",
    "                    rho = np.abs(rho / np.sqrt(height**2 + width**2))\n",
    "                    gt_lines.append((rho, theta))\n",
    "                else:\n",
    "                    gt_lines.append(None)\n",
    "        \n",
    "        # Detect the matching mask by IoU\n",
    "        matched_gt = set()\n",
    "        for pred_idx, pred_mask in enumerate(pred_masks):\n",
    "            best_iou = 0\n",
    "            best_gt_idx = -1\n",
    "            \n",
    "            for gt_idx, gt_mask in enumerate(gt_masks):\n",
    "                if gt_idx in matched_gt:\n",
    "                    continue\n",
    "                iou = compute_iou(pred_mask, gt_mask)\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_gt_idx = gt_idx\n",
    "            \n",
    "            # Consider it a match if IoU > threshold (e.g., 0.5)\n",
    "            #if best_iou > 0.5:\n",
    "            if best_gt_idx >= 0:\n",
    "                matched_gt.add(best_gt_idx)\n",
    "                total_matches += 1\n",
    "                \n",
    "                # Compute the rho_diff and theta_diff if both lines exist\n",
    "                pred_line = pred_lines[pred_idx]\n",
    "                gt_line = gt_lines[best_gt_idx]\n",
    "                \n",
    "                if pred_line is not None and gt_line is not None:\n",
    "                    rho_pred, theta_pred = pred_line\n",
    "                    rho_gt, theta_gt = gt_line\n",
    "                    \n",
    "                    rho_diffs.append(abs(rho_pred - rho_gt))\n",
    "                    angle_diffs.append(theta_diff(theta_pred, theta_gt))\n",
    "        \n",
    "        # Count matching and not matching lines\n",
    "        total_gt_lines += len(gt_masks)\n",
    "        total_pred_lines += len(pred_masks)\n",
    "    \n",
    "    print(f\"Total GT lines: {total_gt_lines}\")\n",
    "    print(f\"Total predicted lines: {total_pred_lines}\")\n",
    "    print(f\"Total matches: {total_matches}\")\n",
    "    print(f\"Lines with coordinate differences computed: {len(rho_diffs)}\")\n",
    "    \n",
    "    if len(rho_diffs) == 0:\n",
    "        return 0, 0\n",
    "    \n",
    "    return np.mean(rho_diffs), np.mean(angle_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f547101a-ee26-4e33-a8b9-b5578aa828cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_line_detection_score(gt_json_path, pred_json_path):\n",
    "\n",
    "    avg_p50, avg_r50 = evaluate_segmentation(gt_json_path, pred_json_path)\n",
    "    rho_diff, angle_diff = combined_analysis(gt_json_path, pred_json_path)\n",
    "\n",
    "    print(f'{avg_p50=}, {avg_r50=}, {angle_diff=}')\n",
    "\n",
    "    lds = avg_p50 + avg_r50 + 2 * angle_diff\n",
    "    print(f'LDS = {lds}')\n",
    "    return lds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6982579e-7bee-4a45-ad2e-ee610370bc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_json_path = 'dataset/test/test.json'\n",
    "pred_json_path = 'output/269017_264097.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2d521f9-6ccc-4b93-9814-c5047b5788fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.37s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.271\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.507\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.263\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.149\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.570\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.865\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.072\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.285\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.308\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.159\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.583\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:15<00:00, 26.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total GT lines: 3328\n",
      "Total predicted lines: 3511\n",
      "Total matches: 2743\n",
      "Lines with coordinate differences computed: 2741\n",
      "avg_p50=np.float64(0.5072826385527931), avg_r50=np.float64(0.2852463942307692), angle_diff=np.float64(0.997930951995745)\n",
      "LDS = 2.7883909367750523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lds=compute_line_detection_score(gt_json_path, pred_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30eaff38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il voto è: 17.6\n"
     ]
    }
   ],
   "source": [
    "baseline_1=2.0\n",
    "baseline_2=2.9\n",
    "\n",
    "def metrica_valutazione(lds, maxValue=2.95):\n",
    "    if lds < baseline_1:\n",
    "        print(\"Niente\")\n",
    "        return 0\n",
    "    elif baseline_1 <= lds <= baseline_2:\n",
    "        return 15 + 3*((lds - baseline_1)/ ((baseline_2 - baseline_1)))\n",
    "    else:\n",
    "        return 18 + 2*((lds - baseline_2)/ ((maxValue - baseline_2)))\n",
    "    \n",
    "print(\"Il voto è:\", round(metrica_valutazione(2.77),1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
